{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from random import randrange\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(path_to_data):\n",
    "    with open(path_to_data) as f:\n",
    "        data = []\n",
    "\n",
    "        col_names = None\n",
    "\n",
    "        for row in csv.reader(f):\n",
    "            if not col_names:\n",
    "                col_names = row\n",
    "                col_names[0] = 'age'\n",
    "            else:\n",
    "                data.append([float(i) for i in row])\n",
    "\n",
    "    return col_names, data\n",
    "\n",
    "def prepare_data(data):\n",
    "    \"\"\"\n",
    "    Use z-score of input feature values\n",
    "    https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.zscore.html\n",
    "    https://en.wikipedia.org/wiki/Feature_scaling#Standardization_(Z-score_Normalization)\n",
    "    \"\"\"\n",
    "    feature_vectors = []\n",
    "    output_classes = []\n",
    "    \n",
    "    for entry in data:\n",
    "        feature_vectors.append(entry[0:-1])\n",
    "        output_classes.append([entry[-1]])\n",
    "        \n",
    "    feature_vectors = np.array(feature_vectors).astype(np.float64)\n",
    "    feature_vectors = np.apply_along_axis(stats.zscore, 0, feature_vectors)\n",
    "        \n",
    "    return feature_vectors, np.array(output_classes), np.hstack((feature_vectors, np.array(output_classes)))\n",
    "\n",
    "def split_data(all_data, train_perc=0.85, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    num_train = math.floor(train_perc * len(all_data))\n",
    "    \n",
    "    use_data = copy.deepcopy(all_data)\n",
    "    \n",
    "    np.random.shuffle(use_data)\n",
    "    \n",
    "    training = []\n",
    "    while len(training) < num_train:\n",
    "        sample, use_data = use_data[-1], use_data[:-1]\n",
    "        \n",
    "        training.append(sample)\n",
    "    testing = use_data\n",
    "    \n",
    "    training_xs = []\n",
    "    training_ys = []\n",
    "    for ind in range(len(training)):\n",
    "        training_xs.append(training[ind][0:-1])\n",
    "        training_ys.append(training[ind][-1])\n",
    "    \n",
    "    testing_xs = []\n",
    "    testing_ys = []\n",
    "    for ind in range(len(testing)):\n",
    "        testing_xs.append(testing[ind][0:-1])\n",
    "        testing_ys.append(testing[ind][-1])\n",
    "        \n",
    "    training_ys = np.expand_dims(training_ys, 1)\n",
    "    testing_ys = np.expand_dims(testing_ys, 1)\n",
    "        \n",
    "    return ((np.array(training_xs), np.array(training_ys).astype(int)), (np.array(testing_xs), np.array(testing_ys).astype(int)))\n",
    "\n",
    "def split_into_k((xs, ys), k):\n",
    "    xs_copy = list(copy.deepcopy(xs))\n",
    "    ys_copy = list(copy.deepcopy(ys))\n",
    "    \n",
    "    xs_ys_pairs = []\n",
    "\n",
    "    fold_len = int(len(xs) / k)\n",
    "    \n",
    "    for _ in range(k):\n",
    "        this_fold_xs = []\n",
    "        this_fold_ys = []\n",
    "        \n",
    "        while len(this_fold_xs) < fold_len:\n",
    "            ind = randrange(len(xs_copy))\n",
    "            this_fold_xs.append(xs_copy.pop(ind))\n",
    "            this_fold_ys.append(ys_copy.pop(ind))\n",
    "        \n",
    "        xs_ys_pairs.append((np.array(this_fold_xs), np.array(this_fold_ys)))\n",
    "        \n",
    "    return xs_ys_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_by_class(data):\n",
    "    by_class = {}\n",
    "    for sample in data:\n",
    "        class_val = sample[-1]\n",
    "        if not by_class.get(class_val):\n",
    "            by_class[class_val] = []\n",
    "        \n",
    "        by_class[class_val].append(sample[0:-1])\n",
    "        \n",
    "    return {k: np.array(v) for k, v in by_class.items()}\n",
    "\n",
    "def _class_stats_helper(feature_vectors):\n",
    "    statistics = []\n",
    "    \n",
    "    for col_ind in range(feature_vectors.shape[1]):\n",
    "        col_vals = feature_vectors[:, col_ind]\n",
    "        mean = np.mean(col_vals)\n",
    "        stddev = np.std(col_vals)\n",
    "        num_vals = len(col_vals)\n",
    "        \n",
    "        statistics.append((mean, stddev, num_vals))\n",
    "        \n",
    "    return statistics\n",
    "\n",
    "def class_stats(samples):\n",
    "    by_class = data_by_class(samples)\n",
    "    stats = {}\n",
    "    \n",
    "    for class_val, class_samples in by_class.items():\n",
    "        stats[class_val] = _class_stats_helper(class_samples)\n",
    "        \n",
    "    return stats\n",
    "\n",
    "def calc_gaussian_prob(x, mean, stddev):\n",
    "    e = np.exp(-((x - mean) ** 2 / (2 * stddev ** 2)))\n",
    "    return (1 / (np.sqrt(2 * np.pi) * stddev)) * e\n",
    "\n",
    "def _calc_class_helper(statistics, feature_vector):\n",
    "    total_samples = sum([statistics[class_val][0][2] for class_val in statistics])\n",
    "    class_probs = {}\n",
    "    \n",
    "    for class_val, class_stats in statistics.items():\n",
    "        class_probs[class_val] = statistics[class_val][0][2] / float(total_samples)\n",
    "        for feature_ind in range(len(class_stats)):\n",
    "            mean, stddev, _ = class_stats[feature_ind]\n",
    "            class_probs[class_val] *= calc_gaussian_prob(feature_vector[feature_ind], mean, stddev)\n",
    "            \n",
    "    return class_probs\n",
    "\n",
    "def calc_class(statistics, feature_vectors):\n",
    "    classes = []\n",
    "    \n",
    "    for feature_vector in feature_vectors:\n",
    "        class_probs = _calc_class_helper(statistics, feature_vector)\n",
    "        _class = 1 if class_probs[1.0] >= class_probs[0.0] else 0\n",
    "        classes.append([_class])\n",
    "        \n",
    "    return np.array(classes)\n",
    "\n",
    "def calc_error(ys, pred_ys):\n",
    "    error = (pred_ys != ys).sum().astype(float) / len(ys)\n",
    "    accuracy = np.mean(pred_ys == ys)\n",
    "    return error, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272 training samples\n",
      "31 testing samples\n"
     ]
    }
   ],
   "source": [
    "names, data_points = load_csv('../data/orig_raw.csv')\n",
    "all_xs, all_ys, adjusted_data = prepare_data(data_points)\n",
    "training, testing = split_data(adjusted_data, train_perc=0.90)\n",
    "print('{} training samples'.format(len(training[0])))\n",
    "print('{} testing samples'.format(len(testing[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_error=0.154166666667 all_accuracy=0.845833333333\n",
      "training_error=0.158088235294, training_accuracy=0.841911764706\n",
      "testing_error=0.193548387097, testing_accuracy=0.806451612903\n"
     ]
    }
   ],
   "source": [
    "all_stats = class_stats(np.hstack((xs, ys)))\n",
    "all_pred_ys = calc_class(all_stats, xs)\n",
    "all_error, all_accuracy = calc_error(ys, all_pred_ys)\n",
    "print('all_error={} all_accuracy={}'.format(all_error, all_accuracy))\n",
    "\n",
    "training_statistics = class_stats(np.hstack((training[0], training[1])))\n",
    "training_pred_ys = calc_class(training_statistics, training[0])\n",
    "training_error, training_accuracy = calc_error(training[1], training_pred_ys)\n",
    "print('training_error={}, training_accuracy={}'.format(training_error, training_accuracy))\n",
    "\n",
    "testing_pred_ys = calc_class(training_statistics, testing[0])\n",
    "testing_error, testing_accuracy = calc_error(testing[1], testing_pred_ys)\n",
    "print('testing_error={}, testing_accuracy={}'.format(testing_error, testing_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=2 error=0.191176470588\n",
      "k=5 error=0.111111111111\n",
      "k=10 error=0.0740740740741\n",
      "k=25 error=0.0\n",
      "lowest_error=0.0\n"
     ]
    }
   ],
   "source": [
    "ks = [2, 5, 10, 25]\n",
    "k_errors = []\n",
    "k_training = []\n",
    "\n",
    "for k in ks:\n",
    "    all_training_xs_ys_pairs = split_into_k(training, k)\n",
    "    holdout_errors = []\n",
    "    holdout_training = []\n",
    "    \n",
    "    for holdout_ind in range(len(all_training_xs_ys_pairs)):\n",
    "        training_copy = copy.deepcopy(all_training_xs_ys_pairs)\n",
    "        holdout_xs, holdout_ys = training_copy.pop(holdout_ind)\n",
    "        xs = training_copy[0][0]\n",
    "        ys = training_copy[0][1]\n",
    "        \n",
    "        for ind in range(1, len(training_copy)):\n",
    "            a_fold_xs, a_fold_ys = training_copy[ind]\n",
    "            xs = np.concatenate((xs, a_fold_xs), axis=0)\n",
    "            ys = np.concatenate((ys, a_fold_ys), axis=0)\n",
    "            \n",
    "        statistics = class_stats(np.hstack((xs, ys)))\n",
    "        pred_ys = calc_class(statistics, holdout_xs)\n",
    "        error, accuracy = calc_error(holdout_ys, pred_ys)\n",
    "            \n",
    "        holdout_errors.append(error)\n",
    "        holdout_training.append(statistics)\n",
    "        \n",
    "    min_error_ind = holdout_errors.index(min(holdout_errors))\n",
    "        \n",
    "    holdout_error = holdout_errors[min_error_ind]\n",
    "    k_errors.append(holdout_error)\n",
    "    best_training = holdout_training[min_error_ind]\n",
    "    k_training.append(best_training)\n",
    "    \n",
    "    print('k={} error={}').format(k, holdout_error)\n",
    "    \n",
    "lowest_error_ind = k_errors.index(min(k_errors))\n",
    "lowest_error = k_errors[lowest_error_ind]\n",
    "best_training = k_training[lowest_error_ind]\n",
    "\n",
    "print('lowest_error={}'.format(lowest_error))\n",
    "# print('best_weights={}'.format(best_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_error=0.145833333333 all_accuracy=0.854166666667\n"
     ]
    }
   ],
   "source": [
    "all_pred_ys = calc_class(best_training, xs)\n",
    "all_error, all_accuracy = calc_error(ys, all_pred_ys)\n",
    "print('all_error={} all_accuracy={}'.format(all_error, all_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
